This project is going to be a command line application that runs on our local machines using Node.js. The purpose of this application is to crawl a 
website and produce a report of the internal linking structure of the website. Basically which pages link to which other pages on the site. This is a
tool that would be traditionally used by web marketers or SEO (Search Engine Optimisation) experts.
1. First we create a new repo in github for the project that we are starting. Next, we clone that repository inside a folder where we want to create
the app using the command "git clone <repo link>"
2. Next, we install NVM or the node version. After that we will use the command "nvm install <version>" followed by the command "nvm use <version>"
3. Next, to check whether everything is working, we will create a main.js file and console.log "Hello World". To run it, we will type, "node main.js"
and this starts the node interpreter and passes in main.js as the entry point. It logs "Hello World" and we are good to go. 
4. Running the node kind of manually from the command line, like the node and then the name of a file, it works just fine. But, because we're going to
be installing a test suite and packages, we're actually going to use NPM to manage all that environment and ecosystem. So, inorder to get that going, 
we just run the command "npm init" and press enter to set all the values as default. This will create a package.json file, in this file the only thing
that we need to change at this point is that we need to add a new script that we'll just call "start" that runs "node main.js" for us. So, instead of
manually typing node main.js into the command line, we will type npm start and that will call the script that we just wrote now. The purpose of this is
now that we're using a package.json file, when we pull in dependencies and run our code through npm, the dependencies will be available to our code. 
Similarly, we will be using npm to run our tests so its convenient to have everything in the start command. We run the command once to check if its
working.
5. So, we're going to be doing some test-driven development as we build out this project and in order to do so we need a test suite. So, we're going to
install Jest a fairly popular testing runtime. We can do that by typing, "npm install --save-dev jest". This will creat the package-lock.json file
and the node_modules folder.
6. Now, we don't want these to be uploaded to our repo so we add a ".gitignore" file and add the node_modules to it. We do this because this folder
contains all of the dependencies for our project and we don't want to commit that code to our repository, we just want the code that is unique to
our application. So, we'll keep track of our dependencies in the package.json, which is committed to our source control. So, anytime we pull down this 
repository fresh, it won't have the node modules so a developer will just need to type, 'npm install' in order to install all the dependencies listed
in the package.json.
7. Now, that we have Jest added as a dependency, we will add a script to actually run it. We will swap out the echo command in the test script in
package.json with "jest". Now, if we run 'npm test' it will run and say no tests found so now we are properly calling Jest and now we just need to
add some tests.
8. Now, the first function that we write tests for is going to be called normalize URLs and we will create a file called crawl.js to write that
function in. Usually when we are doing test-driven development, there are three steps, the first step is to stub out the function that we want to test,
the second step is to write the tests for the function and the third step is to go back and actually implement the main crux of the function. Following
this, we will first stub out our function what this really means is that the function does not do anything useful as such but it gives us an idea of 
what goes in and what comes out. Next, we write the test file called crawl.test.js and the way that jest works is that it just automatically looks for
files in your package or in your folder project directory that end in .test.js so it is important that we name it with that suffix. Heading back to our
crawl.js file we will add a module.exports which will make the normalizeURL function available to other JS files that want to import it. Now, we go back
to our test file and import the function as well as two more functions from jest called 'test' and 'expect'. So, the way testing works with Jest is that 
there is a top test function and it takes as input the name of the test that will be the name of our function that we made, normalizeURL. The second 
input is a function and within this function we can use the expect function to do a test. To do that we will first specify what will be the input that 
we will give to the normalizeURL function as the variable 'input' next we will pass the input to the function and save it as the variable 'actual' in 
the sense that this will be the actual output of the input given to the function and then we will define a variable expected that will hold the value 
that we expect the function to give when the specified input is passed to the function. Then we will use the expect function, pass it the variable 
'actual' and use the method 'toEqual' with it and pass it the variable 'expected'. This line says that we are expecting the actual output of normalizeURL 
to equal the expected output that we've specified.If they do equal each other, Jest will log it as a pass test. If they don't equal each other, then jest 
is going to say the test failed. To run the tests we can simply type the command npm test.
9. Now, that our testing environment is ready we will now actually implement the normalizeURL function. Sometimes on the Internet, there are different
URLs that all point to effectively the same page. So 'https://google.com', 'http://google.com' and 'https://Google.com' are all basically URL strings
for the same webpage. So basically, if all these things are put into the normalizeURL function, we want the same thing to come out. Now, we will build
the actual test suite. We will take any of the above URL strings as an input and the first thing that we need to do is strip down the protocol. The 
domain name and the path together make up the address of the webpage. We don't care about query parameters, protocols etc. when it comes to what page 
does this URL represent. And thats how we write our test too, we set the output as the URL that does not contain any of the above. Now, we need to write 
a function to do that to our string. We implemented this function using the built-in URL constructor. This will give us a URL object with a bunch of
properties like hostname and pathname and that's what we are going to return both as a string. Next thing that we want our normalizeURL function to 
handle is trailing slashes. So, we will add a new test to our test suite and in this test as an input we will add a trailing slash on the URL and we
will deal with it in our function as well. Next test we will write is to remove capitals from our URL and normalize them to lowercase. We don't need
to write any extra logic for this because the URL constructor is doing it for us bcoz it knows that URLs are case insensitive.